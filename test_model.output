[33mWARN: gym.spaces.Box autodetected dtype as <type 'numpy.float32'>. Please provide explicit dtype.[0m
Episode: 0
Executing action: tensor([[ 1]])
Reward for action: -11.0
Executing action: tensor([[ 1]])
Reward for action: -11.0
Executing action: tensor([[ 1]])
Reward for action: -12.0
Executing action: tensor([[ 1]])
Reward for action: -13.0
Executing action: tensor([[ 1]])
Reward for action: -14.0
Executing action: tensor([[ 0]])
Reward for action: -15.0
Executing action: tensor([[ 1]])
Reward for action: -15.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 1]])
Reward for action: -16.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Executing action: tensor([[ 1]])
Reward for action: -18.0
Executing action: tensor([[ 0]])
Reward for action: -19.0
Executing action: tensor([[ 1]])
Reward for action: -20.0
Executing action: tensor([[ 0]])
Reward for action: -20.0
Executing action: tensor([[ 1]])
Reward for action: -21.0
Executing action: tensor([[ 1]])
Reward for action: -22.0
Executing action: tensor([[ 1]])
Reward for action: -23.0
Executing action: tensor([[ 0]])
Reward for action: -24.0
Executing action: tensor([[ 1]])
Reward for action: -24.0
Executing action: tensor([[ 1]])
Reward for action: -24.0
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Executing action: tensor([[ 1]])
Reward for action: -27.0
Executing action: tensor([[ 0]])
Reward for action: -28.0
Executing action: tensor([[ 0]])
Reward for action: -28.0
Executing action: tensor([[ 1]])
Reward for action: -29.0
Executing action: tensor([[ 1]])
Reward for action: -30.0
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Executing action: tensor([[ 0]])
Reward for action: -31.0
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Executing action: tensor([[ 0]])
Reward for action: -32.0
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Executing action: tensor([[ 0]])
Reward for action: -33.0
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Executing action: tensor([[ 1]])
Reward for action: -38.0
Executing action: tensor([[ 1]])
Reward for action: -39.0
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Executing action: tensor([[ 1]])
Reward for action: -39.0
Executing action: tensor([[ 0]])
Reward for action: -40.0
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -42.0
Executing action: tensor([[ 0]])
Reward for action: -43.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -44.0
Executing action: tensor([[ 1]])
Reward for action: -45.0
Executing action: tensor([[ 0]])
Reward for action: -46.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -46.0
Executing action: tensor([[ 1]])
Reward for action: -46.0
Executing action: tensor([[ 0]])
Reward for action: -47.0
Executing action: tensor([[ 1]])
Reward for action: -47.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -47.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -48.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -48.0
Executing action: tensor([[ 1]])
Reward for action: -48.0
Executing action: tensor([[ 1]])
Reward for action: -49.0
Executing action: tensor([[ 0]])
Reward for action: -49.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -50.0
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Executing action: tensor([[ 0]])
Reward for action: -51.0
Total reward: -2336.0
Episode: 1
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Executing action: tensor([[ 0]])
Reward for action: -10.0
Executing action: tensor([[ 1]])
Reward for action: -10.0
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Executing action: tensor([[ 0]])
Reward for action: -13.0
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Executing action: tensor([[ 1]])
Reward for action: -15.0
Executing action: tensor([[ 0]])
Reward for action: -16.0
Executing action: tensor([[ 1]])
Reward for action: -16.0
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Executing action: tensor([[ 0]])
Reward for action: -18.0
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Executing action: tensor([[ 0]])
Reward for action: -20.0
Executing action: tensor([[ 0]])
Reward for action: -21.0
Executing action: tensor([[ 0]])
Reward for action: -21.0
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Executing action: tensor([[ 1]])
Reward for action: -22.0
Executing action: tensor([[ 0]])
Reward for action: -23.0
Executing action: tensor([[ 1]])
Reward for action: -23.0
Executing action: tensor([[ 1]])
Reward for action: -23.0
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Executing action: tensor([[ 1]])
Reward for action: -31.0
Executing action: tensor([[ 1]])
Reward for action: -33.0
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Executing action: tensor([[ 0]])
Reward for action: -35.0
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1792.0
Episode: 2
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -44.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1958.0
Episode: 3
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -1510.0
Episode: 4
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1620.0
Episode: 5
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1656.0
Episode: 6
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1892.0
Episode: 7
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1882.0
Episode: 8
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1653.0
Episode: 9
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1484.0
Episode: 10
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1817.0
Episode: 11
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1392.0
Episode: 12
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -1064.0
Episode: 13
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1108.0
Episode: 14
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1529.0
Episode: 15
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1108.0
Episode: 16
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1162.0
Episode: 17
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1671.0
Episode: 18
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -1331.0
Episode: 19
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1652.0
Episode: 20
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1482.0
Episode: 21
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -44.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -44.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -47.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -48.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -48.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -48.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -49.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -50.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -50.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -2350.0
Episode: 22
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1025.0
Episode: 23
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -44.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -2084.0
Episode: 24
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -2037.0
Episode: 25
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1445.0
Episode: 26
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1187.0
Episode: 27
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([121, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Total reward: -1582.0
Episode: 28
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([121, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -973.0
Episode: 29
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1147.0
Episode: 30
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -39.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -43.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -44.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -45.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -46.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -47.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -48.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -49.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -50.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -50.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -51.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -52.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -53.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -54.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -55.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -55.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -55.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -55.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -56.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -56.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -57.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -57.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -57.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -57.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -57.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -58.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -2624.0
Episode: 31
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1182.0
Episode: 32
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1512.0
Episode: 33
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1023.0
Episode: 34
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1271.0
Episode: 35
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1381.0
Episode: 36
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -939.0
Episode: 37
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -876.0
Episode: 38
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1767.0
Episode: 39
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1132.0
Episode: 40
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Total reward: -1295.0
Episode: 41
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([122, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -981.0
Episode: 42
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([121, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -1315.0
Episode: 43
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1465.0
Episode: 44
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1177.0
Episode: 45
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1818.0
Episode: 46
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -36.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -37.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -38.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -40.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -41.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -42.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Total reward: -1965.0
Episode: 47
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1130.0
Episode: 48
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -29.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -30.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -31.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -32.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -33.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -34.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -35.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Total reward: -1540.0
Episode: 49
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -10.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -11.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -12.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -13.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -14.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -15.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -16.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -17.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -18.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -19.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -20.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -21.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -22.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -23.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -24.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -25.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -26.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([123, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([124, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([125, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 1]])
Reward for action: -27.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([126, 5, 1800])
Network input: torch.Size([1, 5, 1800])
Executing action: tensor([[ 0]])
Reward for action: -28.0
Network input: torch.Size([128, 5, 1800])
Network input: torch.Size([127, 5, 1800])
Total reward: -1224.0
Complete
